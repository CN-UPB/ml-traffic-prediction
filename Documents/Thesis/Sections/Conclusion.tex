\section{Future Work and Conclusion}
This last section describes possible approaches for building upon the results of this thesis.
Furthermore, it analyzes and sums up the outcomes. 
\subsection{Future Work}
One of the biggest possible additions to this thesis is testing the results on a live system.
The live system would be perfect to find out how often the user has to retrain the Long Short-Term Memory model or how often the user has to initialize a new Auto-Regressive Integrated Moving Average model.
When recording the live network traffic, the traffic can be put directly into the models and one can compare the predictions directly to the real traffic.
Also, when putting this predicted traffic directly into a Virtual Network Function scaling and placing algorithm, the behaviour of the algorithm can be analyzed.
This behaviour can then lead to first estimates what actual errors are acceptable and at what value the error is growing too big.

Since the performance of the LSTM was so similar to the ARIMA model, one should try to analyze other RNN layers.
Keras supports GRU (Gated Recurrent Units) and ConvLSTM2D (Convolutional LSTM 2-Dimensional) layers.
The works \cite{8717800} \cite{8292737}, already mentioned in the Related Work chapter, both successfully use convolutional RNNs.

Additionally, on-the-fly-learning could be a promising strategy.
When using each new step to directly continue the training of the model, the retraining of the model could possibly be eliminated.
However, one would have to check if a training step after each new value is the optimal way or if the system has to wait until a whole new batch is complete.
When using this approach, other layers likely have to be included in the model.
I surmise that, because the system trains the model with much more data, a dropout layer would have to be included to prevent overfitting.
A dropout layer drops some of the data that passes through it: how much data the layer is dropping can be configured.
Furthermore, other layers also have a dropout parameter (the LSTM layer, for example).
This would have to be included in the experiments as well.

Additionaly the size of the steps may play a role in the prediction quality.
The Abilene set \cite{SNDlib10}, \cite{OrlowskiPioroTomaszewskiWessaely2010}, has just 5-Minute steps.
Maybe the 15-Minute steps have less correlation as they pack more data into one step.
That should also be tested and in a live system the step size could be chosen arbitrarily.
Also a point that calls for tests with a live system.


\subsection{Conclusion}
The goal of this thesis was to analyze if an Long Short-Term Memory model is a viable approach to predicting network traffic in a Network Function Virtualization scenario.
And this goal was fulfilled in part.
The prediction models work well.
When putting traffic in, a usable prediction for the next step can be achieved.
The predicted value can be interpreted in two parts: the change from the previously predicted value and the actual traffic value.
The reliable part of the prediction is the shape of the prediction, does the traffic go up or down in relation to the previously predicted value.
With this prediction the VNF scaling algorithm should be able to correctly scale the VNFs in the correct direction, up or down.
The other part of the prediction the actual network traffic causes the problems.
Depending on the traffic pattern the actual predicted level of traffic can be off of the actual level.
So, when putting an LSTM model before the placing and scaling algorithm it will be able to work with traffic predicted one step into the future.
With these predictions the scaling of the Virtual Network Functions will go in the correct direction, but depending on the traffic pattern the predicted traffic bandwidth will be wrong.
However, all these statements are also true for an Auto-Regressive Integrated Moving Average model.
With these results it should not matter, for the VNF scaling algorithms, if an LSTM or ARIMA model is used.
Maybe with additional test in different scenarios, as described in the previous section, a clear destinction can be made.

With these results I conclude that traffic prediction is a viable solution for NFV scenarios.
Not neccessarily a deep learning approach like an LSTM but ARIMA models can already greatly improve VNF scaling and placing algorithms.
The reuslts show that these algorithms can be changed from reactive to proactive with machine learning models.